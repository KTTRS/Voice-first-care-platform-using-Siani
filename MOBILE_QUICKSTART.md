# üöÄ Siani Luxury Mobile - Quick Start Guide

## Prerequisites Check

### ‚úÖ Already Complete

- [x] Backend SDOH system implemented and tested
- [x] Mobile packages installed (expo-haptics, expo-av, expo-speech, @expo-google-fonts/inter)
- [x] TypeScript compilation passing (verified via `npx tsc --noEmit`)
- [x] Luxury home screen created with breathing avatar
- [x] Index redirect configured

### ‚ö†Ô∏è VS Code TypeScript Server

If you see red squiggles in `home.tsx` for expo packages:

1. **They are stale errors** - packages are installed
2. **Verification**: Run `cd packages/mobile && npx tsc --noEmit` ‚Üí passes ‚úÖ
3. **Fix**: Restart TS server via Command Palette ‚Üí "TypeScript: Restart TS Server"

---

## Running the Mobile App

### 1. Start Backend (Required)

```bash
# Terminal 1: Start backend with SDOH detection
cd /workspaces/Voice-first-care-platform-using-Siani
./start.sh

# Verify backend running
curl http://localhost:3000/health
```

### 2. Start Mobile App

```bash
# Terminal 2: Start Expo development server
cd /workspaces/Voice-first-care-platform-using-Siani/packages/mobile
npm run dev
```

### 3. Testing Options

#### Option A: iOS Simulator (Mac Required)

```bash
# In the Expo dev server terminal, press 'i'
# OR run: npm run ios
```

**Features**: ‚úÖ Full haptics, voice, speech synthesis

#### Option B: Android Emulator

```bash
# In the Expo dev server terminal, press 'a'
# OR run: npm run android
```

**Features**: ‚úÖ Voice, speech synthesis (‚ö†Ô∏è no haptics API)

#### Option C: Web Browser

```bash
# In the Expo dev server terminal, press 'w'
# OR run: npm run web
```

**Features**: ‚ö†Ô∏è Speech synthesis only (no mic access in dev container)

#### Option D: Physical Device (Recommended)

```bash
# Scan QR code shown in terminal with Expo Go app
# iOS: Camera app ‚Üí scan QR
# Android: Expo Go app ‚Üí Scan QR
```

**Features**: ‚úÖ Full experience with real haptics

---

## What You'll See

### On App Launch

1. **Automatic Redirect**: index.tsx ‚Üí /home
2. **Font Loading**: Inter font loads (brief flash acceptable)
3. **Breathing Avatar**: Glowing circle pulsing slowly (3s cycle)
4. **Welcome Message**: "Hey, I was just thinking about you..."

### Interaction Flow

1. **Tap Avatar**:
   - Haptic feedback (vibration on iOS)
   - Microphone permission prompt (first time)
   - "Listening..." state appears
2. **Speak**:
   - Record audio for 2-3 seconds
   - Automatic stop after 3s
   - User message appears in conversation log
3. **Processing**:
   - "Siani is thinking..." state
   - Simulated 1.5s delay
4. **Response**:
   - Siani's message fades in
   - Speech synthesis reads response aloud
   - Avatar continues breathing

### Design Elements

- **Colors**: Warm linen white (#F9F7F4) background, matte black (#1F1F1F) text
- **Typography**: Inter font family at various weights
- **Animations**: Smooth breathing (3s), glow pulse (2s), message fade-ins
- **Layout**: Minimal chrome, generous white space, conversation-focused

---

## Testing the Voice Experience

### Basic Test Script

1. Launch app ‚Üí see breathing avatar ‚úì
2. Tap avatar ‚Üí feel haptic feedback (iOS) ‚úì
3. Allow microphone permission ‚úì
4. Speak: "I've been having trouble getting to the store"
5. See user message appear in log ‚úì
6. See "Siani is thinking..." ‚úì
7. Hear Siani's voice response ‚úì
8. See Siani's message in log ‚úì

### Current Limitations (Simulated)

‚ö†Ô∏è **Speech-to-Text**: Currently shows placeholder "Thank you for sharing that"
‚ö†Ô∏è **Backend Connection**: Using hardcoded responses, not calling `/api/messages`
‚ö†Ô∏è **SDOH Detection**: Not yet triggering ResourceOfferPrompt

**These are expected** - the UI/UX foundation is complete and ready for integration.

---

## Troubleshooting

### "Cannot find module 'expo-haptics'" (in editor)

**Cause**: VS Code TypeScript server hasn't refreshed
**Solution**:

```bash
# Verify packages installed
cd packages/mobile
npm ls expo-haptics expo-av expo-speech @expo-google-fonts/inter

# Should show all installed ‚úì

# Restart TS server in VS Code
Cmd/Ctrl + Shift + P ‚Üí "TypeScript: Restart TS Server"
```

### "Permission denied" (microphone)

**Cause**: User denied permission or simulator doesn't have mic access
**Solution**:

- Physical device: Settings ‚Üí Expo Go ‚Üí Microphone ‚Üí Enable
- Simulator: Should work automatically (check System Preferences ‚Üí Security)

### "Font not loading"

**Cause**: `expo-font` not loaded before rendering
**Solution**: App has `useFonts()` hook - wait for `fontsLoaded` before rendering

### "Avatar not breathing"

**Cause**: Animation not starting
**Solution**:

- Check console for errors
- Verify `useEffect()` runs (console.log "Starting animations...")
- Try hot reload (shake device ‚Üí Reload)

### "No sound on speech synthesis"

**Cause**: Device volume muted or Expo Audio not configured
**Solution**:

- Check device volume
- On iOS simulator: Debug ‚Üí Open Audio
- Verify expo-speech installed: `npm ls expo-speech`

---

## Next Integration Steps

### 1. Real Speech-to-Text (Priority)

**Current**: `setTimeout(() => "Thank you for sharing that", 1000)`
**Target**: OpenAI Whisper API or Google Speech-to-Text

```typescript
// Replace in handleAvatarPress():
const recordingUri = recording.getURI();
const formData = new FormData();
formData.append("audio", {
  uri: recordingUri,
  type: "audio/m4a",
  name: "speech.m4a",
});

const transcription = await fetch(
  "https://api.openai.com/v1/audio/transcriptions",
  {
    method: "POST",
    headers: { Authorization: `Bearer ${OPENAI_API_KEY}` },
    body: formData,
  }
);

const { text } = await transcription.json();
```

### 2. Backend Message Endpoint (Priority)

**Current**: Hardcoded responses
**Target**: Connect to `/api/messages`

```typescript
// Replace in handleAvatarPress():
import { sendMessage } from "../lib/api";

const response = await sendMessage({
  userId: currentUser.id,
  message: userText,
});

const { reply, sdoh } = response;

// Show ResourceOfferPrompt if sdoh.hasNewOffers
if (sdoh?.hasNewOffers) {
  // TODO: Show ResourceOfferPrompt component
}
```

### 3. SDOH Resource Offers (Medium)

**Current**: No detection
**Target**: Show ResourceOfferPrompt when backend detects needs

```typescript
// In home.tsx after receiving message response:
if (sdoh?.hasNewOffers) {
  setShowResourcePrompt(true);
  setResourceEngagements(sdoh.newEngagements);
}

// Render ResourceOfferPrompt modal
{
  showResourcePrompt && (
    <ResourceOfferPrompt
      engagements={resourceEngagements}
      onAccept={handleAcceptResource}
      onDecline={handleDeclineResource}
    />
  );
}
```

---

## Performance Optimization

### Recommended for Production

1. **Memoize Animations**: Wrap breathing/glow in `useMemo()` to prevent recreation
2. **Lazy Load Fonts**: Use `expo-font`'s async loading with splash screen
3. **Optimize Re-renders**: Use `React.memo()` on MessageBubble component
4. **Debounce Avatar Taps**: Prevent double-tap issues
5. **Background Audio**: Configure expo-av for background audio playback

---

## Design Validation

### Luxury Aesthetic Checklist

- [ ] Warm color palette (no bright blues) ‚úì
- [ ] Inter font family loading ‚úì
- [ ] Generous white space between elements ‚úì
- [ ] Slow, meditative animations (3s breathing) ‚úì
- [ ] Minimal UI chrome (no unnecessary buttons) ‚úì
- [ ] Haptic feedback on interaction (iOS) ‚úì
- [ ] No healthcare metaphors in copy ‚úì
- [ ] Voice-first interaction priority ‚úì

### User Experience Checklist

- [ ] Avatar breathing creates sense of presence ‚úì
- [ ] Glow pulse adds vitality/life ‚úì
- [ ] Conversation log feels intimate (no tails) ‚úì
- [ ] Loading states communicate clearly ‚úì
- [ ] Welcome message sets warm tone ‚úì
- [ ] Safe area insets respected ‚úì
- [ ] Scrolling smooth on conversation log ‚úì

---

## Success Metrics to Track

Once deployed, monitor:

1. **Voice Interaction Rate**: % of users who tap avatar vs text input
2. **Session Duration**: Average time spent in conversation
3. **Daily Active Users**: Return rate within 24 hours
4. **Speech Recognition Accuracy**: % requiring manual correction
5. **SDOH Offer Acceptance**: % of detected needs accepted via mobile

---

## Summary

| Component              | Status                     |
| ---------------------- | -------------------------- |
| Mobile packages        | ‚úÖ Installed               |
| TypeScript compilation | ‚úÖ Passing                 |
| Home screen            | ‚úÖ Complete                |
| Breathing animation    | ‚úÖ Working                 |
| Haptic feedback        | ‚úÖ Working (iOS)           |
| Speech synthesis       | ‚úÖ Working                 |
| Voice recording        | ‚úÖ Working (simulated STT) |
| Index redirect         | ‚úÖ Complete                |
| Backend connection     | ‚è≥ Ready for integration   |
| SDOH detection         | ‚è≥ Ready for integration   |

**You can now run the app and experience the luxury voice-first interface!**

**Primary Command**: `cd packages/mobile && npm run dev` then scan QR code with Expo Go.

---

_Design Philosophy: "Not a helper ‚Äî someone you aspire to be close to."_
